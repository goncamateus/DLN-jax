{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "\n",
    "from PIL import Image, ImageEnhance, ImageOps\n",
    "from torchvision.transforms import ToTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(filepath):\n",
    "    img = Image.open(filepath).convert(\"RGB\")\n",
    "    return img\n",
    "\n",
    "\n",
    "def rescale_img(img, scale):\n",
    "    size_in = img.size\n",
    "    new_size_in = tuple([int(x * scale) for x in size_in])\n",
    "    img = img.resize(new_size_in, resample=Image.BICUBIC)\n",
    "    return img\n",
    "\n",
    "\n",
    "def get_patch(img_in, img_tar, patch_size, scale, ix=-1, iy=-1):\n",
    "    (ih, iw) = img_in.size\n",
    "\n",
    "    patch_mult = scale\n",
    "    tp = patch_mult * patch_size\n",
    "    ip = tp // scale\n",
    "\n",
    "    if ix == -1:\n",
    "        ix = random.randrange(0, iw - ip + 1)\n",
    "    if iy == -1:\n",
    "        iy = random.randrange(0, ih - ip + 1)\n",
    "\n",
    "    (tx, ty) = (scale * ix, scale * iy)\n",
    "\n",
    "    img_in = img_in.crop((ty, tx, ty + tp, tx + tp))\n",
    "    img_tar = img_tar.crop((ty, tx, ty + tp, tx + tp))\n",
    "    return img_in, img_tar\n",
    "\n",
    "\n",
    "def augment(img_in, img_tar, flip_h=True, rot=True):\n",
    "    info_aug = {\"flip_h\": False, \"flip_v\": False, \"trans\": False}\n",
    "\n",
    "    if random.random() < 0.5 and flip_h:\n",
    "        img_in = ImageOps.flip(img_in)\n",
    "        img_tar = ImageOps.flip(img_tar)\n",
    "        info_aug[\"flip_h\"] = True\n",
    "\n",
    "    if rot:\n",
    "        if random.random() < 0.5:\n",
    "            img_in = ImageOps.mirror(img_in)\n",
    "            img_tar = ImageOps.mirror(img_tar)\n",
    "            info_aug[\"flip_v\"] = True\n",
    "        if random.random() < 0.5:\n",
    "            img_in = img_in.rotate(180)\n",
    "            img_tar = img_tar.rotate(180)\n",
    "            info_aug[\"trans\"] = True\n",
    "\n",
    "    return img_in, img_tar, info_aug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VOC2007(data.Dataset):\n",
    "    def __init__(\n",
    "        self, img_folder, patch_size, upscale_factor, data_augmentation, transform=None\n",
    "    ):\n",
    "        super(VOC2007, self).__init__()\n",
    "        self.imgFolder = img_folder\n",
    "        self.image_filenames = [\n",
    "            os.path.join(self.imgFolder, x)\n",
    "            for x in os.listdir(self.imgFolder)\n",
    "            if self.is_image_file(x)\n",
    "        ]\n",
    "\n",
    "        self.image_filenames = self.image_filenames\n",
    "        self.patch_size = patch_size\n",
    "        self.upscale_factor = upscale_factor\n",
    "        self.transform = transform\n",
    "        self.data_augmentation = data_augmentation\n",
    "\n",
    "    def is_image_file(self, filename):\n",
    "        return any(\n",
    "            filename.endswith(extension)\n",
    "            for extension in [\".bmp\", \".png\", \".jpg\", \".jpeg\"]\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        ori_img = load_img(self.image_filenames[index])  # PIL image\n",
    "        width, height = ori_img.size\n",
    "        ratio = min(width, height) / 384\n",
    "\n",
    "        newWidth = int(width / ratio)\n",
    "        newHeight = int(height / ratio)\n",
    "        ori_img = ori_img.resize((newWidth, newHeight), Image.LANCZOS)\n",
    "        \n",
    "        high_image = ori_img.copy()\n",
    "        high_image.save(\"high_image.png\")\n",
    "\n",
    "        ## color and contrast *dim*\n",
    "        color_dim_factor = 0.3 * random.random() + 0.7\n",
    "        contrast_dim_factor = 0.3 * random.random() + 0.7\n",
    "        ori_img = ImageEnhance.Color(ori_img).enhance(color_dim_factor)\n",
    "        ori_img = ImageEnhance.Contrast(ori_img).enhance(contrast_dim_factor)\n",
    "\n",
    "        ori_img = cv2.cvtColor((np.asarray(ori_img)), cv2.COLOR_RGB2BGR)  # cv2 image\n",
    "        ori_img = (ori_img.clip(0, 255)).astype(\"uint8\")\n",
    "        low_img = ori_img.astype(\"double\") / 255.0\n",
    "\n",
    "        # generate low-light image\n",
    "        beta = 0.5 * random.random() + 0.5\n",
    "        alpha = 0.1 * random.random() + 0.9\n",
    "        gamma = 3.5 * random.random() + 1.5\n",
    "        low_img = beta * np.power(alpha * low_img, gamma)\n",
    "\n",
    "        low_img = low_img * 255.0\n",
    "        low_img = (low_img.clip(0, 255)).astype(\"uint8\")\n",
    "        low_img = Image.fromarray(cv2.cvtColor(low_img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        img_in, img_tar = low_img, high_image\n",
    "        \n",
    "        if self.data_augmentation:\n",
    "            img_in, img_tar, _ = augment(img_in, img_tar)\n",
    "\n",
    "        if self.transform:\n",
    "            img_in = self.transform(img_in)\n",
    "            img_tar = self.transform(img_tar)\n",
    "\n",
    "        return img_in, img_tar\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the dataset saving the images\n",
    "def save_images(dataset):\n",
    "    # img_in and img_tar are PIL images\n",
    "    for i, (img_in, img_tar) in enumerate(dataset):\n",
    "        img_in.save(f\"../datasets/test/to_report/low/{i}.png\")\n",
    "        img_tar.save(f\"../datasets/test/to_report/high/{i}.png\")        \n",
    "        if i == 15:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VOC2007(\"../datasets/test/VOC2007/JPEGImages\", 128, 4, False)\n",
    "save_images(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
