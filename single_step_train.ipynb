{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "\n",
    "from dm_pix import ssim\n",
    "from dm_pix import psnr\n",
    "from flax.training import train_state\n",
    "\n",
    "from dln.data import get_Low_light_training_set\n",
    "from dln.jax_dln import DLN\n",
    "from dln.jax_data_loader import jnp_data_loader\n",
    "from dln.jax_tv import total_variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def apply_model(state, ll, nl):\n",
    "\n",
    "    def loss_fn(params):\n",
    "        nl_pred = state.apply_fn({\"params\": params}, ll)\n",
    "        ssim_loss = 1 - ssim(nl, nl_pred)\n",
    "        tv_loss = total_variation(nl_pred)\n",
    "        loss = ssim_loss + 0.001 * tv_loss\n",
    "        return jnp.mean(loss), nl_pred\n",
    "\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (loss, nl_pred), grads = grad_fn(state.params)\n",
    "    res_psnr = psnr(nl, nl_pred)\n",
    "    return grads, loss, jnp.mean(res_psnr)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def update_model(state, grads):\n",
    "    return state.apply_gradients(grads=grads)\n",
    "\n",
    "\n",
    "def train_epoch(state, data_loader):\n",
    "    epoch_loss = []\n",
    "    epoch_psnr = []\n",
    "    for ll, nl in data_loader:\n",
    "        grads, loss, res_psnr = apply_model(state, ll, nl)\n",
    "        state = update_model(state, grads)\n",
    "        epoch_loss.append(loss)\n",
    "        epoch_psnr.append(res_psnr)\n",
    "    return state, jnp.mean(epoch_loss), jnp.mean(epoch_psnr)\n",
    "\n",
    "\n",
    "def create_train_state(rng, model, lr):\n",
    "    state = train_state.TrainState.create(\n",
    "        apply_fn=model.apply,\n",
    "        params=model.init(rng, jnp.ones((1, 256, 256, 3)))[\"params\"],\n",
    "        tx=optax.adam(learning_rate=lr),\n",
    "    )\n",
    "    return state\n",
    "\n",
    "\n",
    "rng = jax.random.key(0)\n",
    "rng, init_rng = jax.random.split(rng)\n",
    "model = DLN(64)\n",
    "state = create_train_state(init_rng, model, 1e-3)\n",
    "train_set = get_Low_light_training_set(\n",
    "    upscale_factor=1, patch_size=128, data_augmentation=True\n",
    ")\n",
    "data_loader = jnp_data_loader(train_set, batch_size=4)\n",
    "for epoch in range(100):\n",
    "    state, loss, res_psnr = train_epoch(state, data_loader)\n",
    "    print(f\"Epoch: {epoch}, Loss: {loss}, PSNR: {res_psnr}\")\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
