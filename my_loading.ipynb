{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax\n",
    "import torch\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from dln.data import get_Low_light_training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = get_Low_light_training_set(\n",
    "        upscale_factor=1, patch_size=128, data_augmentation=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_data_loader(dataset, batch_size, shuffle=True):\n",
    "    indices = np.arange(len(dataset))\n",
    "    if shuffle:\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(dataset) - batch_size + 1, batch_size):\n",
    "        excerpt = indices[start_idx : start_idx + batch_size]\n",
    "        batch = [dataset[i] for i in excerpt]\n",
    "        low_light, normal_light = zip(*batch)\n",
    "        jaxed_low_light = jnp.array(low_light)\n",
    "        jaxed_normal_light = jnp.array(normal_light)\n",
    "        yield jnp.transpose(jaxed_low_light, (0, 2, 3, 1)), jnp.transpose(\n",
    "            jaxed_normal_light, (0, 2, 3, 1)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax import linen as nn\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    output_size: int\n",
    "    kernel_size: tuple\n",
    "    stride: tuple\n",
    "    padding: str  # 'SAME' or 'VALID'\n",
    "    use_bias: bool = True\n",
    "    use_bn: bool = False\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, training: bool = True):\n",
    "        x = nn.Conv(features=self.output_size, \n",
    "                    kernel_size=self.kernel_size, \n",
    "                    strides=self.stride, \n",
    "                    padding=self.padding, \n",
    "                    use_bias=self.use_bias)(x)\n",
    "        if self.use_bn:\n",
    "            x = nn.BatchNorm(use_running_average=not training)(x)\n",
    "        x = nn.PReLU()(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreDLN(nn.Module):\n",
    "    dim: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, inputs, training: bool = True):\n",
    "        x = (inputs - 0.5) * 2\n",
    "        x_bright = jnp.max(x, axis=3, keepdims=True)\n",
    "        x_in = jnp.concatenate((x, x_bright), axis=3)\n",
    "        feat1 = ConvBlock(output_size=2 * self.dim, kernel_size=3, stride=1, padding=1)(\n",
    "            x_in, training=training\n",
    "        )\n",
    "        feat2 = ConvBlock(output_size=self.dim, kernel_size=3, stride=1, padding=1)(\n",
    "            feat1, training=training\n",
    "        )\n",
    "        return feat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchConvBlock(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, kernel_size, stride, padding, bias=True, isuseBN=False):\n",
    "        super(TorchConvBlock, self).__init__()\n",
    "        self.isuseBN = isuseBN\n",
    "        self.conv = torch.nn.Conv2d(input_size, output_size, kernel_size, stride, padding, bias=bias)\n",
    "        if self.isuseBN:\n",
    "            self.bn = nn.BatchNorm2d(output_size)\n",
    "        self.act = torch.nn.PReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        if self.isuseBN:\n",
    "            out = self.bn(out)\n",
    "        out = self.act(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "sample_input = torch.stack([train_set[i][0] for i in range(32)])\n",
    "torch_convblock = TorchConvBlock(4, 128, 3, 1, 1)\n",
    "x = (sample_input -0.5) * 2\n",
    "x_bright, _ = torch.max(x, dim=1, keepdim=True)\n",
    "x_in = torch.cat((x, x_bright), dim=1)\n",
    "print(x_in.shape)\n",
    "conv_block = torch_convblock(x_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "feat1 = ConvBlock(output_size=128, kernel_size=3, stride=1, padding=1)\n",
    "jax_input = jnp.ones((32, 128, 128, 4))\n",
    "variables = feat1.init(jax.random.PRNGKey(0), jax_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1\n",
      "Image Shapes\n",
      "(32, 128, 128, 3) (32, 128, 128, 3)\n",
      "ConvBlock\n",
      "(32, 128, 128, 4)\n",
      "(32, 128, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "for iteration, batch in enumerate(numpy_data_loader(train_set, 32), 1):\n",
    "    print(\"iteration\", iteration)\n",
    "    LL_t, NL_t = batch\n",
    "    print(\"Image Shapes\")\n",
    "    print(LL_t.shape, NL_t.shape)\n",
    "    print(\"ConvBlock\")\n",
    "    x = (LL_t - 0.5) * 2\n",
    "    x_bright = jnp.max(x, axis=3, keepdims=True)\n",
    "    x_in = jnp.concatenate((x, x_bright), axis=3)\n",
    "    print(x_in.shape)\n",
    "    output = feat1.apply(variables, x_in, training=True)\n",
    "    print(output.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_blocks = PreDLN(dim=64)\n",
    "sample_input = jnp.ones((32, 128, 128, 3))\n",
    "variables = two_blocks.init(jax.random.PRNGKey(0), sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1\n",
      "Image Shapes\n",
      "(32, 128, 128, 3) (32, 128, 128, 3)\n",
      "ConvBlock\n",
      "(32, 128, 128, 64)\n"
     ]
    }
   ],
   "source": [
    "for iteration, batch in enumerate(numpy_data_loader(train_set, 32), 1):\n",
    "    print(\"iteration\", iteration)\n",
    "    LL_t, NL_t = batch\n",
    "    print(\"Image Shapes\")\n",
    "    print(LL_t.shape, NL_t.shape)\n",
    "    print(\"ConvBlock\")\n",
    "    output = two_blocks.apply(variables, LL_t, training=True)\n",
    "    print(output.shape)\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
